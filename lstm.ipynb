{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project, COMS 4995_005, Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Information\n",
    "\n",
    "Team Member1 (Name,UNI): Richard Kennedy, rk2860\n",
    "\n",
    "Python Version: 2\n",
    "Utilizing Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cPickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torchtext.vocab as Vocab\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import PIL\n",
    "import random\n",
    "import numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=3.37s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "cap = dset.CocoCaptions(root = './train2014',\n",
    "                        annFile = 'annotations/captions_train2014.json',\n",
    "                        transform= transforms.Compose([transforms.Resize([224, 224]), transforms.ToTensor()]))\n",
    "\n",
    "res = models.resnet50(pretrained=True)\n",
    "vdim = 100\n",
    "rSize = 2048\n",
    "x = Vocab.GloVe(name='6B', dim= vdim)\n",
    "\n",
    "paddSize =  rSize - vdim\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "a = x.vectors[x.stoi['man']]\n",
    "print a.size()\n",
    "b = torch.FloatTensor(paddSize).zero_()\n",
    "paddedVec = torch.cat((a, b), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HELLO\n"
     ]
    }
   ],
   "source": [
    "print \"HELLO\"\n",
    "# img, target = cap[0]\n",
    "# words = ['StopLSTM'] + target[0].split(' ') + ['EndLSTM']\n",
    "# print words\n",
    "\n",
    "\n",
    "# print wordVec(Vocab[words[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size, res50):\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        self.Esize = embed_size\n",
    "        self.Hsize = hidden_size\n",
    "        self.Wix = nn.Linear(embed_size, hidden_size)\n",
    "        self.Wim = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Wfx = nn.Linear(embed_size, hidden_size)\n",
    "        self.Wfm = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Wox = nn.Linear(embed_size, hidden_size)\n",
    "        self.Wom = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Wcx = nn.Linear(embed_size, hidden_size)\n",
    "        self.Wcm = nn.Linear(hidden_size, hidden_size)\n",
    "        \n",
    "        self.Dense1 = nn.Linear(hidden_size, 1000)\n",
    "        self.Dense2 = nn.Linear(1000, 25000)\n",
    "        #self.Dense3 = nn.Linear(10000, 400000)\n",
    "        #res50 = torchvision.models.resnet50(pretrained=True)\n",
    "        self.res50NoGrad = torch.nn.Sequential(*list(res50.children())[:-2])\n",
    "        #Every layer besides the last layer does not need to be trained\n",
    "        for param in self.res50NoGrad.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        #set embed_size to dimensions of self.res50Last\n",
    "        #output should be second to last layer\n",
    "        self.res50Last = torch.nn.Sequential(list(res50.children())[-2])\n",
    "        \n",
    "        \n",
    "        #self.glove = Vocab.GloVe(name='840B', dim= embed_size)\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, x, m = None, c = None, CNN = False ):\n",
    "        \n",
    "        if not CNN:\n",
    "            #glove requires x to be one hot word encoding?\n",
    "            #x = self.glove(x)\n",
    "            i = F.sigmoid(self.Wix(x)+self.Wim(m))\n",
    "            f = F.sigmoid(self.Wfx(x)+self.Wfm(m))\n",
    "            o = F.sigmoid(self.Wox(x)+self.Wom(m))\n",
    "            h = F.tanh(self.Wcx(x) + self.Wcm(m))\n",
    "            newC = f*c + i*h\n",
    "            newM = o*newC\n",
    "            #prediction dimension should line up with vocab_size\n",
    "            #fine tune hidden dimension to make that work\n",
    "            \n",
    "            #log_softmax might not be necessary -> due to backprop\n",
    "            \n",
    "            #calculations: hidden dimensions = 50, embed_size = 2048, vocab_size not used\n",
    "            #prediction = F.log_softmax(newM,)\n",
    "            \n",
    "            pred1 = F.relu(self.Dense1(newM))\n",
    "            prediction = F.relu(self.Dense2(pred1))\n",
    "            #prediction = self.Dense3(pred2)\n",
    "            prediction = F.log_softmax(prediction)\n",
    "            \n",
    "            return prediction, newC, newM\n",
    "        \n",
    "        else:\n",
    "            x = self.res50NoGrad(x)\n",
    "            x = self.res50Last(x)\n",
    "            x = x.resize(1, self.Esize)\n",
    "            i = F.sigmoid(self.Wix(x))\n",
    "            f = F.sigmoid(self.Wfx(x))\n",
    "            o = F.sigmoid(self.Wox(x))\n",
    "            h = F.tanh(self.Wcx(x))\n",
    "            c = i*h\n",
    "            m = o*c\n",
    "            \n",
    "            return None, c, m\n",
    "\n",
    "# net = LSTM(2048, 50, res)\n",
    "# img, target = cap[0]\n",
    "# img = img.unsqueeze(0)\n",
    "# junk, c0, m0 =  net.forward(Variable(img), CNN = True)\n",
    "\n",
    "# a = x.vectors[x.stoi['man']]\n",
    "# b = torch.FloatTensor(1998).zero_()\n",
    "# paddedVec = torch.cat((a, b), 0)\n",
    "\n",
    "# pred, c0, m0 = net.forward(Variable(paddedVec), m = m0, c = c0)\n",
    "# pred = pred.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Richard/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:56: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0, LOSS: 10.1395254135\n",
      "EPOCH: 0, LOSS: 10.0036272049\n",
      "9.34074115753\n",
      "EPOCH: 0, LOSS: 9.20677968651\n",
      "7.43363904953\n",
      "EPOCH: 0, LOSS: 8.24207474828\n",
      "11.1552495956\n",
      "EPOCH: 0, LOSS: 6.79219589213\n",
      "10.9621248245\n",
      "EPOCH: 0, LOSS: 7.9854288898\n",
      "10.4130058289\n",
      "EPOCH: 0, LOSS: 7.47164356261\n",
      "10.5925998688\n",
      "EPOCH: 0, LOSS: 7.26797458172\n",
      "10.8862047195\n",
      "EPOCH: 0, LOSS: 9.79891041189\n",
      "4.42850875854\n",
      "EPOCH: 0, LOSS: 7.80174483359\n",
      "9.21429634094\n",
      "EPOCH: 0, LOSS: 7.30309289187\n",
      "11.0460977554\n",
      "EPOCH: 0, LOSS: 7.43882817358\n",
      "5.0699801445\n",
      "EPOCH: 0, LOSS: 6.78464717209\n",
      "5.88101148605\n",
      "EPOCH: 0, LOSS: 6.72407829106\n",
      "11.1056604385\n",
      "EPOCH: 0, LOSS: 7.41315808982\n",
      "3.84374570847\n",
      "EPOCH: 0, LOSS: 6.86710194349\n",
      "0.890671491623\n",
      "EPOCH: 0, LOSS: 6.4943426609\n",
      "5.93923664093\n",
      "EPOCH: 0, LOSS: 6.26645407259\n",
      "6.22255086899\n",
      "EPOCH: 0, LOSS: 6.43520167351\n",
      "11.6732730865\n",
      "EPOCH: 0, LOSS: 6.48453542054\n",
      "1.97042393684\n",
      "EPOCH: 0, LOSS: 7.35856286168\n",
      "78.4253463745\n",
      "EPOCH: 0, LOSS: 6.68931759\n",
      "11.5995121002\n",
      "EPOCH: 0, LOSS: 6.04572455883\n",
      "11.6850376129\n",
      "EPOCH: 0, LOSS: 5.95495910347\n",
      "12.8390321732\n",
      "EPOCH: 0, LOSS: 9.74148782551\n",
      "12.0198764801\n",
      "EPOCH: 0, LOSS: 7.12011773616\n",
      "8.32511138916\n",
      "EPOCH: 0, LOSS: 6.92772657186\n",
      "8.81688404083\n",
      "EPOCH: 0, LOSS: 9.15643501177\n",
      "156.96925354\n",
      "EPOCH: 0, LOSS: 6.55218718208\n",
      "12.4674186707\n",
      "EPOCH: 0, LOSS: 7.08002915666\n",
      "3.75695943832\n",
      "EPOCH: 0, LOSS: 6.71433670431\n",
      "6.25455951691\n",
      "EPOCH: 0, LOSS: 6.35116893947\n",
      "12.3863801956\n",
      "EPOCH: 0, LOSS: 6.76429206371\n",
      "9.88578224182\n",
      "EPOCH: 0, LOSS: 6.39878514707\n",
      "3.39956474304\n",
      "EPOCH: 0, LOSS: 6.61656578183\n",
      "1.67982673645\n",
      "EPOCH: 0, LOSS: 6.2197400701\n",
      "12.6754951477\n",
      "EPOCH: 0, LOSS: 7.25407470375\n",
      "5.31643486023\n",
      "EPOCH: 0, LOSS: 7.26013671458\n",
      "12.7396535873\n",
      "EPOCH: 0, LOSS: 25.2513887363\n",
      "7.16484355927\n",
      "EPOCH: 0, LOSS: 7.30328373432\n",
      "6.84340286255\n",
      "EPOCH: 0, LOSS: 6.20075566411\n",
      "9.81959629059\n",
      "EPOCH: 0, LOSS: 8.00710057039\n",
      "6.91237688065\n",
      "EPOCH: 0, LOSS: 6.15742595155\n",
      "5.00441360474\n",
      "EPOCH: 0, LOSS: 6.71572053239\n",
      "13.2144365311\n",
      "EPOCH: 0, LOSS: 6.87042303145\n",
      "13.6755056381\n",
      "EPOCH: 0, LOSS: 10.9278876941\n",
      "13.4391231537\n",
      "EPOCH: 0, LOSS: 6.72564106337\n",
      "9.91700267792\n",
      "EPOCH: 0, LOSS: 7.07064771086\n",
      "5.63120555878\n",
      "EPOCH: 0, LOSS: 7.58599819005\n",
      "3.86158633232\n",
      "EPOCH: 0, LOSS: 7.27151968598\n",
      "13.0787086487\n",
      "EPOCH: 0, LOSS: 6.48365178108\n",
      "1.64528882504\n",
      "EPOCH: 0, LOSS: 6.05801903188\n",
      "8.07483005524\n",
      "EPOCH: 0, LOSS: 7.35820498466\n",
      "2.42649722099\n",
      "EPOCH: 0, LOSS: 6.86958721757\n",
      "4.47899436951\n",
      "EPOCH: 0, LOSS: 7.39491567433\n",
      "3.29585528374\n",
      "EPOCH: 0, LOSS: 6.54490288019\n",
      "5.04867506027\n",
      "EPOCH: 0, LOSS: 6.69538731337\n",
      "5.01636505127\n",
      "EPOCH: 0, LOSS: 6.94908196509\n",
      "3.73611235619\n",
      "EPOCH: 0, LOSS: 7.5060038209\n",
      "12.7266263962\n",
      "EPOCH: 0, LOSS: 7.38161474302\n",
      "12.8433542252\n",
      "EPOCH: 0, LOSS: 6.9319769609\n",
      "1.0441801548\n",
      "EPOCH: 0, LOSS: 7.25890624881\n",
      "12.628903389\n",
      "EPOCH: 0, LOSS: 10.6544655275\n",
      "5.55294322968\n",
      "EPOCH: 0, LOSS: 7.64975206196\n",
      "2.4904282093\n",
      "EPOCH: 0, LOSS: 6.78214090943\n",
      "4.71198177338\n",
      "EPOCH: 0, LOSS: 9.94435667336\n",
      "4.88694477081\n",
      "EPOCH: 0, LOSS: 6.99542848945\n",
      "2.82209157944\n",
      "EPOCH: 0, LOSS: 7.34550390244\n",
      "8.35185909271\n",
      "EPOCH: 0, LOSS: 7.50273858309\n",
      "12.2570695877\n",
      "EPOCH: 0, LOSS: 6.95625924766\n",
      "8.01143741608\n",
      "EPOCH: 0, LOSS: 6.86096354067\n",
      "0.741869866848\n",
      "EPOCH: 0, LOSS: 48.5226207864\n",
      "3.66969180107\n",
      "EPOCH: 0, LOSS: 7.03692880034\n",
      "3.16853356361\n",
      "EPOCH: 0, LOSS: 7.36748862982\n",
      "4.71333646774\n",
      "EPOCH: 0, LOSS: 9.07698216319\n",
      "6.07698965073\n",
      "EPOCH: 0, LOSS: 6.76779971182\n",
      "1.14596319199\n",
      "EPOCH: 0, LOSS: 453.495749203\n",
      "6.60535907745\n",
      "EPOCH: 0, LOSS: 76.5880683589\n",
      "7.67017221451\n",
      "EPOCH: 0, LOSS: 7.44053260684\n",
      "12.1335391998\n",
      "EPOCH: 0, LOSS: 24.1747514457\n",
      "10.8057498932\n",
      "EPOCH: 0, LOSS: 10.1265824395\n",
      "6.90780925751\n",
      "EPOCH: 0, LOSS: 23.4421576679\n",
      "7.26640319824\n",
      "EPOCH: 0, LOSS: 7.82088013649\n",
      "10.5613174438\n",
      "EPOCH: 0, LOSS: 7.07251408219\n",
      "2.11013913155\n",
      "EPOCH: 0, LOSS: 7.49241727471\n",
      "1.33045709133\n",
      "EPOCH: 0, LOSS: 40.8006865716\n",
      "1.08937633038\n",
      "EPOCH: 0, LOSS: 9.81891489148\n",
      "3.23857593536\n",
      "EPOCH: 0, LOSS: 7.70170824051\n",
      "11.3553180695\n",
      "EPOCH: 0, LOSS: 22.8653228474\n",
      "11.20570755\n",
      "EPOCH: 0, LOSS: 7.39609103322\n",
      "1.20886194706\n",
      "EPOCH: 0, LOSS: 7.42929092646\n",
      "1.37659883499\n",
      "EPOCH: 0, LOSS: 35.2629392278\n",
      "2.21126580238\n",
      "EPOCH: 0, LOSS: 6.89264680743\n",
      "11.017780304\n",
      "EPOCH: 0, LOSS: 22.6389274681\n",
      "11.1571302414\n",
      "EPOCH: 0, LOSS: 7.1680484736\n",
      "5.46929311752\n",
      "EPOCH: 0, LOSS: 7.15056092978\n",
      "10.9103374481\n",
      "EPOCH: 0, LOSS: 6.93812334538\n",
      "10.9614877701\n",
      "EPOCH: 0, LOSS: 12.5328451228\n",
      "11.3374223709\n",
      "EPOCH: 0, LOSS: 13.4353900748\n",
      "11.8604307175\n",
      "EPOCH: 0, LOSS: 9.09226632178\n",
      "3.62628936768\n",
      "EPOCH: 0, LOSS: 8.02798869491\n",
      "6.63372516632\n",
      "EPOCH: 0, LOSS: 7.4027977252\n",
      "10.9112329483\n",
      "EPOCH: 0, LOSS: 7.46142566323\n",
      "1.68420648575\n",
      "EPOCH: 0, LOSS: 7.7447972846\n",
      "0.531806051731\n",
      "EPOCH: 0, LOSS: 8.16933201015\n",
      "7.82786035538\n",
      "EPOCH: 0, LOSS: 10696.3694769\n",
      "10.8091688156\n",
      "EPOCH: 0, LOSS: 28.8677417088\n",
      "7.2575302124\n",
      "EPOCH: 0, LOSS: 10.5721864843\n",
      "6.6166009903\n",
      "EPOCH: 0, LOSS: 7.43056345522\n",
      "11.2077932358\n",
      "EPOCH: 0, LOSS: 21.6288845575\n",
      "5.2767663002\n",
      "EPOCH: 0, LOSS: 8.09431083322\n",
      "6.58470010757\n",
      "EPOCH: 0, LOSS: 8.27222048402\n",
      "10.5006446838\n",
      "EPOCH: 0, LOSS: 18.0544101691\n",
      "10.5554914474\n",
      "EPOCH: 0, LOSS: 7.91155666351\n",
      "10.9015760422\n",
      "EPOCH: 0, LOSS: 7.66840060294\n",
      "10.99421978\n",
      "EPOCH: 0, LOSS: 8.31307694554\n",
      "10.860786438\n",
      "EPOCH: 0, LOSS: 9.63801490784\n",
      "10.6774482727\n",
      "EPOCH: 0, LOSS: 7.91024827003\n",
      "10.7298116684\n",
      "EPOCH: 0, LOSS: 7.98198689461\n",
      "11.0541067123\n",
      "EPOCH: 0, LOSS: 972.907102069\n",
      "3.93894195557\n",
      "EPOCH: 0, LOSS: 142.343745365\n",
      "10.791302681\n",
      "EPOCH: 0, LOSS: 379.753996263\n",
      "10.6951551437\n",
      "EPOCH: 0, LOSS: 56.4696621132\n",
      "10.7708806992\n",
      "EPOCH: 0, LOSS: 5203.56469254\n",
      "10.7133102417\n",
      "EPOCH: 0, LOSS: 49.9890463072\n",
      "11.191450119\n",
      "EPOCH: 0, LOSS: 631.182223521\n",
      "13.493970871\n",
      "EPOCH: 0, LOSS: 75.3352286482\n",
      "10.505607605\n",
      "EPOCH: 0, LOSS: 56.1123580778\n",
      "10.5392198563\n",
      "EPOCH: 0, LOSS: 10.00755988\n",
      "1.16832411289\n",
      "EPOCH: 0, LOSS: 57.7836486942\n",
      "0.930576562881\n",
      "EPOCH: 0, LOSS: 225.328828692\n",
      "10.5866260529\n",
      "EPOCH: 0, LOSS: 30.3855772996\n",
      "4.607421875\n",
      "EPOCH: 0, LOSS: 160.951464174\n",
      "10.4858837128\n",
      "EPOCH: 0, LOSS: 8.94321450949\n",
      "10.5878782272\n",
      "EPOCH: 0, LOSS: 82.9998005211\n",
      "10.6069507599\n",
      "EPOCH: 0, LOSS: 367.758181822\n",
      "10.4634122849\n",
      "EPOCH: 0, LOSS: 1589.06053676\n",
      "2.42830300331\n",
      "EPOCH: 0, LOSS: 59.6363362026\n",
      "2.11534237862\n",
      "EPOCH: 0, LOSS: 159.46230726\n",
      "10.6027297974\n",
      "EPOCH: 0, LOSS: 8.2499625349\n",
      "10.618803978\n",
      "EPOCH: 0, LOSS: 1527.6852148\n",
      "10.5983791351\n",
      "EPOCH: 0, LOSS: 21.8869628513\n",
      "3.18723845482\n",
      "EPOCH: 0, LOSS: 107.217561263\n",
      "10.9796247482\n",
      "EPOCH: 0, LOSS: 12.970659883\n",
      "10.8004302979\n",
      "EPOCH: 0, LOSS: 2112.89487854\n",
      "10.7316265106\n",
      "EPOCH: 0, LOSS: 35.5559646161\n",
      "10.6999931335\n",
      "EPOCH: 0, LOSS: 106.880636759\n",
      "1.77590572834\n",
      "EPOCH: 0, LOSS: 17.5303499103\n",
      "10.8839445114\n",
      "EPOCH: 0, LOSS: 198.632848319\n",
      "9.72371196747\n",
      "EPOCH: 0, LOSS: 55.0737771142\n",
      "2.37926125526\n",
      "EPOCH: 0, LOSS: 8.22385758638\n",
      "10.5460414886\n",
      "EPOCH: 0, LOSS: 158.679671731\n",
      "10.6880884171\n",
      "EPOCH: 0, LOSS: 7.55741151452\n",
      "1.1175506115\n",
      "EPOCH: 0, LOSS: 8.41514791369\n",
      "8.94920253754\n",
      "EPOCH: 0, LOSS: 7.43390246749\n",
      "10.8190469742\n",
      "EPOCH: 0, LOSS: 55.9554382598\n",
      "10.7836112976\n",
      "EPOCH: 0, LOSS: 47.1190528893\n",
      "7.42103242874\n",
      "EPOCH: 0, LOSS: 160004.867016\n",
      "10.509270668\n",
      "EPOCH: 0, LOSS: 195.45602107\n",
      "10.5099668503\n",
      "EPOCH: 0, LOSS: 736.944189918\n",
      "10.5560235977\n",
      "EPOCH: 0, LOSS: 10.5330549312\n",
      "10.763343811\n",
      "EPOCH: 0, LOSS: 2575.85619631\n",
      "10.6490182877\n",
      "EPOCH: 0, LOSS: 10.2276626956\n",
      "10.4569349289\n",
      "EPOCH: 0, LOSS: 8.91349956989\n",
      "2.99611401558\n",
      "EPOCH: 0, LOSS: 221.640856874\n",
      "2.28772783279\n",
      "EPOCH: 0, LOSS: 28.9498464966\n",
      "10.9820251465\n",
      "EPOCH: 0, LOSS: 8.20199053049\n",
      "1.60012447834\n",
      "EPOCH: 0, LOSS: 5791.83203002\n",
      "5.26732587814\n",
      "EPOCH: 0, LOSS: 351.967629426\n",
      "10.4664678574\n",
      "EPOCH: 0, LOSS: 3341.11441328\n",
      "669.487548828\n",
      "EPOCH: 0, LOSS: 423.417088119\n",
      "1.13258135319\n",
      "EPOCH: 0, LOSS: 159.948596215\n",
      "10.9315156937\n",
      "EPOCH: 0, LOSS: 305.957581701\n",
      "7.69908189774\n",
      "EPOCH: 0, LOSS: 8.43059890985\n",
      "10.3023147583\n",
      "EPOCH: 0, LOSS: 8.55176919222\n",
      "10.3491573334\n",
      "EPOCH: 0, LOSS: 8.50565582037\n",
      "10.4393701553\n",
      "EPOCH: 0, LOSS: 8.53085193515\n",
      "0.804548799992\n",
      "EPOCH: 0, LOSS: 8.43148560584\n",
      "1.23127698898\n",
      "EPOCH: 0, LOSS: 8.40706861258\n",
      "10.4433040619\n",
      "EPOCH: 0, LOSS: 8.22292360067\n",
      "10.3715810776\n",
      "EPOCH: 0, LOSS: 12.4611496544\n",
      "10.4835643768\n",
      "EPOCH: 0, LOSS: 8.34832988679\n",
      "10.8316106796\n",
      "EPOCH: 0, LOSS: 8.22759113491\n",
      "1.72496497631\n",
      "EPOCH: 0, LOSS: 8.66522173285\n",
      "10.4285736084\n",
      "EPOCH: 0, LOSS: 8.72456644773\n",
      "10.4735736847\n",
      "EPOCH: 0, LOSS: 10.106229375\n",
      "0.917385339737\n",
      "EPOCH: 0, LOSS: 8.4632898277\n",
      "0.9883659482\n",
      "EPOCH: 0, LOSS: 8.35171692967\n",
      "2.71485567093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0, LOSS: 8.15125870705\n",
      "10.2404565811\n",
      "EPOCH: 0, LOSS: 8.43091962099\n",
      "2.25981259346\n",
      "EPOCH: 0, LOSS: 8.46407219172\n",
      "10.8293142319\n",
      "EPOCH: 0, LOSS: 47.903093453\n",
      "10.5809955597\n",
      "EPOCH: 0, LOSS: 8.32775066018\n",
      "10.4140377045\n",
      "EPOCH: 0, LOSS: 8.44869211078\n",
      "10.385430336\n",
      "EPOCH: 0, LOSS: 9.12931621313\n",
      "10.3748426437\n",
      "EPOCH: 0, LOSS: 8.3285217005\n",
      "10.6791200638\n",
      "EPOCH: 0, LOSS: 8.69353141606\n",
      "10.4651880264\n",
      "EPOCH: 0, LOSS: 43636.2739758\n",
      "10.3221311569\n",
      "EPOCH: 0, LOSS: 7014.48194186\n",
      "10.3225183487\n",
      "EPOCH: 0, LOSS: 1037.21173392\n",
      "10.4344177246\n",
      "EPOCH: 0, LOSS: 30.8357066494\n",
      "10.9031162262\n",
      "EPOCH: 0, LOSS: 8.20691363633\n",
      "10.8138151169\n",
      "EPOCH: 0, LOSS: 17.0958448434\n",
      "10.5049791336\n",
      "EPOCH: 0, LOSS: 8.83190348506\n",
      "2.70125889778\n",
      "EPOCH: 0, LOSS: 8.66657783031\n",
      "10.3165512085\n",
      "EPOCH: 0, LOSS: 8.65772653699\n",
      "10.5501241684\n",
      "EPOCH: 0, LOSS: 8.21343978047\n",
      "10.6054410934\n",
      "EPOCH: 0, LOSS: 8885.22042447\n",
      "10.329785347\n",
      "EPOCH: 0, LOSS: 1107.2513007\n",
      "7.95067834854\n",
      "EPOCH: 0, LOSS: 24.6170675421\n",
      "10.2484922409\n",
      "EPOCH: 0, LOSS: 28.8730917001\n",
      "2.20424962044\n",
      "EPOCH: 0, LOSS: 9.42877745032\n",
      "10.1273565292\n",
      "EPOCH: 0, LOSS: 43.9713253954\n",
      "10.1266307831\n",
      "EPOCH: 0, LOSS: 10.9485224031\n",
      "10.1266307831\n",
      "EPOCH: 0, LOSS: 9.29235623837\n",
      "0.0171381849796\n",
      "EPOCH: 0, LOSS: 9.87111339723\n",
      "10.1266307831\n",
      "EPOCH: 0, LOSS: 9.49786409189\n",
      "10.1266307831\n",
      "EPOCH: 0, LOSS: 9.34013281145\n",
      "10.1266307831\n",
      "EPOCH: 0, LOSS: 9.54852218797\n",
      "10.1266307831\n",
      "EPOCH: 0, LOSS: 9.66932496451\n",
      "10.1266307831\n",
      "EPOCH: 0, LOSS: 9.11666052895\n",
      "10.1266307831\n",
      "EPOCH: 0, LOSS: 9.32287681013\n",
      "10.1266307831\n",
      "EPOCH: 0, LOSS: 10.0267595445\n",
      "10.1266307831\n",
      "EPOCH: 0, LOSS: 10.1266314602\n",
      "10.1266307831\n",
      "EPOCH: 0, LOSS: 10.1266307831\n",
      "10.1266307831\n",
      "EPOCH: 0, LOSS: 18.024627037\n",
      "10.1266307831\n",
      "EPOCH: 0, LOSS: 10.1266307831\n",
      "10.1266307831\n",
      "EPOCH: 0, LOSS: 562.67126339\n",
      "10.1266307831\n",
      "EPOCH: 0, LOSS: 10.1266307831\n",
      "10.1266307831\n",
      "EPOCH: 0, LOSS: 129.658977938\n",
      "10.1266307831\n",
      "EPOCH: 0, LOSS: 10.1519716072\n",
      "10.1266307831\n",
      "EPOCH: 0, LOSS: 21801.6813833\n",
      "10.1266307831\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-f3f1786ab502>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mlogLoss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Richard/anaconda2/lib/python2.7/site-packages/torch/optim/sgd.pyc\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     98\u001b[0m                         \u001b[0md_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##Train\n",
    "\n",
    "\n",
    "startW = 'start'\n",
    "endW = 'stop'\n",
    "## was lazy and used cat and dog as start and stop word. \n",
    "## Definetely going to have to change that\n",
    "net = LSTM(rSize, vdim, res)\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(filter(lambda p: p.requires_grad,net.parameters()), lr=0.001, momentum=.2)\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for epoch in range(0, 1000):\n",
    "    permute = np.random.permutation(len(cap))\n",
    "    logLoss = 0.0\n",
    "    numGoals = 0\n",
    "    numGenerals = 0\n",
    "    localMins = 0\n",
    "    torch.save(net, str(epoch)+'LSTM.pt')\n",
    "    for i in range(0, len(cap)):\n",
    "        img, target = cap[permute[i]]\n",
    "        words = [startW] + target[0].split(' ') + [endW]\n",
    "        length = len(words)\n",
    "        img = img.unsqueeze(0)\n",
    "        junk, c0, m0 =  net.forward(Variable(img), CNN = True)\n",
    "        fullPred = None\n",
    "        fullAnsw = None\n",
    "        flip = True\n",
    "        \n",
    "        \n",
    "        for j in range(0, length-1):\n",
    "            lossPlus = 0\n",
    "            #Going to need larger word corpus\n",
    "            if words[j].lower() in x.stoi and words[j+1].lower() in x.stoi:\n",
    "\n",
    "                a = x.vectors[x.stoi[words[j].lower()]]\n",
    "                b = torch.FloatTensor(paddSize).zero_()\n",
    "                paddedVec = torch.cat((a, b), 0)\n",
    "                pred, c0, m0 = net.forward(Variable(paddedVec), m = m0, c = c0)\n",
    "                \n",
    "                index = x.stoi[words[j+1].lower()]\n",
    "                if index < 25000:\n",
    "                    answer = torch.zeros([1]).type('torch.LongTensor')\n",
    "                    answer[0] = index\n",
    "                    \n",
    "                    \n",
    "                else:\n",
    "                    continue\n",
    "                #temp = torch.FloatTensor(400000).zero_()\n",
    "                #temp[x.stoi[words[j+1].lower()]] = 1\n",
    "\n",
    "#                 answer = x.vectors[x.stoi[words[j+1].lower()]]\n",
    "#                 answer = answer.unsqueeze(0)\n",
    "\n",
    "                \n",
    "                \n",
    "#                 #Trying to remove the Local Minimums\n",
    "#                 dist1 = torch.dist(pred, Variable(answer)).data[0]\n",
    "#                 dist2 = torch.dist(pred, Variable(x.vectors[x.stoi[random.choice(x.stoi.keys())]])).data[0]\n",
    "#                 if abs(dist1 - dist2) <= .8 or dist1 >= dist2:\n",
    "#                     #pred.data[0] = Variable(x.vectors[x.stoi[random.choice(x.stoi.keys())]]).data[0]\n",
    "                    \n",
    "#                     numGoals+=1\n",
    "#                     lossPlus+= .35\n",
    "                    \n",
    "#                 if torch.dist(pred, Variable(x.vectors[x.stoi['goals_none']])).data[0] <= 4.0:\n",
    "                    \n",
    "#                     numGenerals+=1   \n",
    "#                     #pred.data[0] = Variable(x.vectors[x.stoi[random.choice(x.stoi.keys())]]).data[0]\n",
    "#                     lossPlus+=.5\n",
    "                \n",
    "# #                 if dist1 < 3.5 and dist1 > 2.5:\n",
    "# #                     localMins+= 1\n",
    "# #                     lossPlus += .25\n",
    "               \n",
    "                \n",
    "                \n",
    "                loss = criterion(pred, Variable(answer))\n",
    "                #loss.data[0]+=lossPlus\n",
    "                loss.backward(retain_graph = True)\n",
    "        \n",
    "                optimizer.step()\n",
    "\n",
    "                logLoss += loss.data[0]\n",
    "                #logLoss += lossPlus\n",
    "                if counter % 100 == 99:    \n",
    "                    print(\"EPOCH: \"+str(epoch) + \", LOSS: \" + str(logLoss/100))\n",
    "                    print loss.data[0]\n",
    "                    #print(\"goals_none: \"+ str(numGoals) + \", generals: \"+str(numGenerals))\n",
    "#                     numGoals = 0\n",
    "#                     numGenerals = 0\n",
    "                    logLoss = 0.0\n",
    "        \n",
    "                if counter == 0:\n",
    "                    print(\"EPOCH: \"+str(epoch) + \", LOSS: \" + str(logLoss))\n",
    "                    \n",
    "                counter+=1   \n",
    "\n",
    "#                 if flip:\n",
    "#                     fullPred = pred.unsqueeze(0)\n",
    "#                     fullAnsw = answer.unsqueeze(0)\n",
    "#                     flip = False\n",
    "#                 else:\n",
    "#                     answer = answer.unsqueeze(0)\n",
    "#                     pred = pred.unsqueeze(0)\n",
    "#                     fullPred = torch.cat((fullPred, pred), 0)\n",
    "#                     fullAnsw = torch.cat((fullAnsw, answer), 0)\n",
    "                    \n",
    "                    \n",
    "\n",
    "\n",
    "        \n",
    "#         loss = criterion(fullPred, Variable(fullAnsw))\n",
    "#         loss.data[0]+=lossPlus\n",
    "#         loss.backward()\n",
    "        \n",
    "#         optimizer.step()\n",
    "\n",
    "#         logLoss += loss.data[0]\n",
    "#         if counter % 100 == 99:    \n",
    "#             print(\"EPOCH: \"+str(epoch) + \", LOSS: \" + str(logLoss/100))\n",
    "#             logLoss = 0.0\n",
    "        \n",
    "#         if counter == 0:\n",
    "#             print(\"EPOCH: \"+str(epoch) + \", LOSS: \" + str(logLoss))\n",
    "\n",
    "#         counter+=1   \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'A man riding skis down a snow covered slope.', u'Someone cross country skiing in their back yard', u'A person is skiing over a snowy hill.', u'A man is trying to ski down a small hill.', u'A person on skis in the snow with trees in back.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Richard/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:56: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-10.1388587952\n",
      "-10.1388587952\n",
      "7\n",
      "the\n",
      "the\n",
      "0 0\n"
     ]
    }
   ],
   "source": [
    "#torch.save(net, str(epoch)+'DenseLSTM.pt')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "net = LSTM(rSize, vdim, res)\n",
    "\n",
    "def createInverse(dic):\n",
    "    new_dic ={}\n",
    "    for key in dic:\n",
    "        new_dic[dic[key]] = key\n",
    "    \n",
    "    return new_dic\n",
    "\n",
    "invert = createInverse(x.stoi)\n",
    "\n",
    "def closest(vec, n=1):\n",
    "    \"\"\"\n",
    "    Find the closest words for a given vector\n",
    "    \"\"\"\n",
    "#     all_dists = [(w,torch.dist(vec, Variable(x.vectors[x.stoi[w]]))) for w in x.stoi]\n",
    "#     return sorted(all_dists, key=lambda t: t[1].data.numpy()[0])[:n]\n",
    "    \n",
    "    maximum = 0\n",
    "    maxIndex = 0\n",
    "    for i in range(0, len(vec)):\n",
    "        if vec[i] > maximum:\n",
    "            maxIndex = i\n",
    "            maximum = vec[i]\n",
    "    maxIndex2 = 0\n",
    "    maximum = 0\n",
    "    for i in range(0, len(vec)):\n",
    "        if vec[i] > maximum and i != maxIndex:\n",
    "            maxIndex2 = i\n",
    "            maximum = vec[i]\n",
    "    \n",
    "    return maxIndex, maxIndex2\n",
    "\n",
    "def whenNotSorted(vec):\n",
    "    before = vec[0]\n",
    "    for i in range(1, len(vec)):\n",
    "        if before >= vec[i]:\n",
    "            before = vec[i]\n",
    "        else:\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "img, target = cap[10]\n",
    "print target\n",
    "img = img.unsqueeze(0)\n",
    "junk, c0, m0 =  net.forward(Variable(img), CNN = True)\n",
    "a = x.vectors[x.stoi['dog'.lower()]]\n",
    "b = torch.FloatTensor(paddSize).zero_()\n",
    "paddedVec = torch.cat((a, b), 0)\n",
    "prediction, c0, m0 = net.forward(Variable(paddedVec), m = m0, c = c0)\n",
    "print prediction.data[0][400]\n",
    "print prediction.data[0][700]\n",
    "strn, listVec =  closest(prediction.data[0], 1)\n",
    "\n",
    "print whenNotSorted(prediction.data[0])\n",
    "print invert[listVec]\n",
    "newWord = invert[strn]\n",
    "print newWord\n",
    "\n",
    "print listVec, strn\n",
    "k = input()\n",
    "#print strn\n",
    "while True:\n",
    "    a = x.vectors[x.stoi[newWord.lower()]]\n",
    "    b = torch.FloatTensor(paddSize).zero_()\n",
    "    paddedVec = torch.cat((a, b), 0)\n",
    "    prediction, c0, m0 = net.forward(Variable(paddedVec), m = m0, c = c0)\n",
    "    strn, listVec =  closest(prediction.data[0], 1)\n",
    "    print invert[listVec]\n",
    "    newWord = invert[strn]\n",
    "    print newWord\n",
    "    #print strn\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'goals_none', Variable containing:\n",
      " 2.6643\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'65stk', Variable containing:\n",
      " 2.7356\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'__________________________________', Variable containing:\n",
      " 2.7474\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'prohertrib', Variable containing:\n",
      " 2.7507\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'http://www.oklahomacitynationalmemorial.org', Variable containing:\n",
      " 2.7676\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'tissottiming.com', Variable containing:\n",
      " 2.8126\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'____________________________________________', Variable containing:\n",
      " 2.8153\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'timewrn', Variable containing:\n",
      " 2.8185\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'_____________________________________________', Variable containing:\n",
      " 2.8302\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'www.slarmy.org', Variable containing:\n",
      " 2.8431\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'http://www.co.mo.md.us', Variable containing:\n",
      " 2.8616\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'nortelnet', Variable containing:\n",
      " 2.8627\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'dellcptr', Variable containing:\n",
      " 2.8732\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'likewise', Variable containing:\n",
      " 2.8736\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'30-270', Variable containing:\n",
      " 2.9003\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'http://www.nwguild.org', Variable containing:\n",
      " 2.9027\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'naborsind', Variable containing:\n",
      " 2.9378\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'devonengy', Variable containing:\n",
      " 2.9411\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'k587-1', Variable containing:\n",
      " 2.9422\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'mo95', Variable containing:\n",
      " 2.9434\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'http://www.mediabynumbers.com', Variable containing:\n",
      " 2.9440\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'k977-1', Variable containing:\n",
      " 2.9451\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'k978-1', Variable containing:\n",
      " 2.9455\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'js94bb', Variable containing:\n",
      " 2.9464\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'str95bb', Variable containing:\n",
      " 2.9468\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'bulletinyyy', Variable containing:\n",
      " 2.9470\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'srivalo', Variable containing:\n",
      " 2.9492\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'piyanart', Variable containing:\n",
      " 2.9493\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'bdb94', Variable containing:\n",
      " 2.9495\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'bb96', Variable containing:\n",
      " 2.9503\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'www.caib.us', Variable containing:\n",
      " 2.9647\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'brohd', Variable containing:\n",
      " 2.9725\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'kd97', Variable containing:\n",
      " 2.9781\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'http://www.nifc.gov/', Variable containing:\n",
      " 2.9810\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'biotechtrst', Variable containing:\n",
      " 2.9834\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'svahng', Variable containing:\n",
      " 2.9885\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'24aou94', Variable containing:\n",
      " 2.9922\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'instead', Variable containing:\n",
      " 2.9963\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'instance', Variable containing:\n",
      " 2.9977\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'goal_pittsburgh', Variable containing:\n",
      " 2.9987\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'kuhdz', Variable containing:\n",
      " 3.0022\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'bb94', Variable containing:\n",
      " 3.0023\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'brought', Variable containing:\n",
      " 3.0031\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'em96', Variable containing:\n",
      " 3.0049\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'moreover', Variable containing:\n",
      " 3.0106\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'js03', Variable containing:\n",
      " 3.0166\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'goal_florida', Variable containing:\n",
      " 3.0284\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'rohsh', Variable containing:\n",
      " 3.0448\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'presumably', Variable containing:\n",
      " 3.0452\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'organgn', Variable containing:\n",
      " 3.0501\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'js04bb', Variable containing:\n",
      " 3.0597\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'rw95', Variable containing:\n",
      " 3.0604\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'str94', Variable containing:\n",
      " 3.0642\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'nasdaq100', Variable containing:\n",
      " 3.0679\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'gph04bb', Variable containing:\n",
      " 3.0699\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'oly-2004-tennis', Variable containing:\n",
      " 3.0700\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'nokiacorp', Variable containing:\n",
      " 3.0773\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'besides', Variable containing:\n",
      " 3.0795\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'greg.wilcoxdailynews.com', Variable containing:\n",
      " 3.0801\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'coludata.co.uk', Variable containing:\n",
      " 3.0817\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'oly-2004-cycling', Variable containing:\n",
      " 3.0952\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'indnsia', Variable containing:\n",
      " 3.0970\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'rohch', Variable containing:\n",
      " 3.1073\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'goal_ottawa', Variable containing:\n",
      " 3.1079\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'goal_toronto', Variable containing:\n",
      " 3.1088\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'goal_boston', Variable containing:\n",
      " 3.1125\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'bringing', Variable containing:\n",
      " 3.1144\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'yr.ago', Variable containing:\n",
      " 3.1187\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'oly-2004-gymnastics', Variable containing:\n",
      " 3.1223\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'referring', Variable containing:\n",
      " 3.1273\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'http://www.statoil.com', Variable containing:\n",
      " 3.1314\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'meantime', Variable containing:\n",
      " 3.1373\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'supposed', Variable containing:\n",
      " 3.1401\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'noting', Variable containing:\n",
      " 3.1434\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'nasdaq100tr', Variable containing:\n",
      " 3.1465\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'genlelec', Variable containing:\n",
      " 3.1496\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'strikeouts_clemens', Variable containing:\n",
      " 3.1508\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'wc2003-wis', Variable containing:\n",
      " 3.1519\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'indeed', Variable containing:\n",
      " 3.1525\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'goal_montreal', Variable containing:\n",
      " 3.1544\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'interbk', Variable containing:\n",
      " 3.1548\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'pyoot', Variable containing:\n",
      " 3.1595\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'oly-2004-fhockey', Variable containing:\n",
      " 3.1643\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'turned', Variable containing:\n",
      " 3.1683\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'kd94', Variable containing:\n",
      " 3.1684\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'ooooooooooooooooooooooooooooooooooooooo', Variable containing:\n",
      " 3.1690\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'goal_colorado', Variable containing:\n",
      " 3.1766\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'canyonres', Variable containing:\n",
      " 3.1854\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'kd96', Variable containing:\n",
      " 3.1946\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'period_8', Variable containing:\n",
      " 3.1975\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'david.lazarus@latimes.com', Variable containing:\n",
      " 3.2005\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'28aou94', Variable containing:\n",
      " 3.2006\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'oly-2004-box', Variable containing:\n",
      " 3.2041\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'wrldcom', Variable containing:\n",
      " 3.2049\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'#ukqec', Variable containing:\n",
      " 3.2061\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'turning', Variable containing:\n",
      " 3.2071\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'http://www.storaenso.com', Variable containing:\n",
      " 3.2105\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'kd95', Variable containing:\n",
      " 3.2155\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'fahnt', Variable containing:\n",
      " 3.2216\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'404-222-8268', Variable containing:\n",
      " 3.2219\n",
      "[torch.FloatTensor of size 1]\n",
      ")]\n",
      "(u'goals_none', Variable containing:\n",
      " 2.6616\n",
      "[torch.FloatTensor of size 1]\n",
      ")\n",
      "Variable containing:\n",
      " 3.9846\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 4.8796\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print closest(prediction, 100)\n",
    "\n",
    "print strn[0]\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "print torch.dist(Variable(x.vectors[x.stoi[random.choice(x.stoi.keys())]]), Variable(x.vectors[x.stoi['goals_none']]))\n",
    "\n",
    "print torch.dist(Variable(x.vectors[x.stoi['snow']]), Variable(x.vectors[x.stoi['ice']]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 4.0605\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print torch.dist(Variable(x.vectors[x.stoi['hand']]), Variable(x.vectors[x.stoi['finger']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101640\n"
     ]
    }
   ],
   "source": [
    "print x.stoi['petunia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
