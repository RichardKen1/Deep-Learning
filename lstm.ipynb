{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW2, COMS 4995_005, Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Information\n",
    "\n",
    "Team Member1 (Name,UNI): Richard Kennedy, rk2860\n",
    "\n",
    "Python Version: 2\n",
    "Utilizing Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cPickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torchtext.vocab as Vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ship\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Richard/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:75: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "     def __init__(self, embed_size, hidden_size, vocab_size, num_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.Wix = nn.Linear(embded_size, hidden_size)\n",
    "        self.Wim = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Wfx = nn.Linear(embed_size, hidden_size)\n",
    "        self.Wfm = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Wox = nn.Linear(embed_size, hidden_size)\n",
    "        self.Wom = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Wcx = nn.Linear(embed_size, hidden_size)\n",
    "        self.Wcm = nn.Linear(hidden_size, hidden_size)\n",
    "        \n",
    "        res50 = torchvision.models.resnet50(pretrained=True)\n",
    "        self.res50NoGrad = torch.nn.Sequential(*list(res50.children())[:-2])\n",
    "        #Every layer besides the last layer does not need to be trained\n",
    "        for param in self.res50NoGrad.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        #set embed_size to dimensions of self.res50Last\n",
    "        #output should be second to last layer\n",
    "        self.res50Last = torch.nn.Sequential(*list(res50.children())[-1])\n",
    "        \n",
    "        \n",
    "        self.glove = Vocab.GloVe(name='840B', dim= embed_size)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, x, m = None, c = None, CNN = False ):\n",
    "        \n",
    "        if not CNN:\n",
    "            #glove requires x to be one hot word encoding?\n",
    "            x = self.glove(x)\n",
    "            i = F.sigmoid(self.Wix(x)+self.Wim(m))\n",
    "            f = F.sigmoid(self.Wfx(x)+self.Wfm(m))\n",
    "            o = F.sigmoid(self.Wox(x)+self.Wom(m))\n",
    "            h = F.tanh(Wcx(x) + Wcm(m))\n",
    "            newC = f*c + i*h\n",
    "            newM = o*newC\n",
    "            #prediction dimension should line up with vocab_size\n",
    "            #fine tune hidden dimension to make that work\n",
    "            \n",
    "            #log_softmax might not be necessary -> due to backprop\n",
    "            prediction = F.log_softmax(newM,)\n",
    "            \n",
    "            return prediction, newC, newM\n",
    "        \n",
    "        else:\n",
    "            x= self.res50NoGrad(x)\n",
    "            x = self.res50Last(x)\n",
    "            i = F.sigmoid(self.Wix(x))\n",
    "            f = F.sigmoid(self.Wfx(x))\n",
    "            o = F.sigmoid(self.Wox(x))\n",
    "            h = F.tanh(Wcx(x))\n",
    "            c = f*c + i*h\n",
    "            m = o*c\n",
    "            \n",
    "            return None, c, m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
