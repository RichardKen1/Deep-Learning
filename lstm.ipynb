{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project, COMS 4995_005, Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Information\n",
    "\n",
    "Team Member1 (Name,UNI): Richard Kennedy, rk2860\n",
    "\n",
    "Python Version: 2\n",
    "Utilizing Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cPickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torchtext.vocab as Vocab\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=2.52s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400000/400000 [00:51<00:00, 7714.52it/s]\n"
     ]
    }
   ],
   "source": [
    "cap = dset.CocoCaptions(root = './train2014',\n",
    "                        annFile = 'annotations/captions_train2014.json',\n",
    "                        transform= transforms.Compose([transforms.Resize([224, 224]), transforms.ToTensor()]))\n",
    "\n",
    "res = models.resnet50(pretrained=True)\n",
    "vdim = 100\n",
    "rSize = 2048\n",
    "x = Vocab.GloVe(name='6B', dim= vdim)\n",
    "\n",
    "paddSize =  rSize - vdim\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "a = x.vectors[x.stoi['man']]\n",
    "print a.size()\n",
    "b = torch.FloatTensor(paddSize).zero_()\n",
    "paddedVec = torch.cat((a, b), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HELLO\n"
     ]
    }
   ],
   "source": [
    "print \"HELLO\"\n",
    "# img, target = cap[0]\n",
    "# words = ['StopLSTM'] + target[0].split(' ') + ['EndLSTM']\n",
    "# print words\n",
    "\n",
    "\n",
    "# print wordVec(Vocab[words[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size, res50):\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        self.Esize = embed_size\n",
    "        self.Hsize = hidden_size\n",
    "        self.Wix = nn.Linear(embed_size, hidden_size)\n",
    "        self.Wim = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Wfx = nn.Linear(embed_size, hidden_size)\n",
    "        self.Wfm = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Wox = nn.Linear(embed_size, hidden_size)\n",
    "        self.Wom = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Wcx = nn.Linear(embed_size, hidden_size)\n",
    "        self.Wcm = nn.Linear(hidden_size, hidden_size)\n",
    "        \n",
    "        #res50 = torchvision.models.resnet50(pretrained=True)\n",
    "        self.res50NoGrad = torch.nn.Sequential(*list(res50.children())[:-2])\n",
    "        #Every layer besides the last layer does not need to be trained\n",
    "        for param in self.res50NoGrad.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        #set embed_size to dimensions of self.res50Last\n",
    "        #output should be second to last layer\n",
    "        self.res50Last = torch.nn.Sequential(list(res50.children())[-2])\n",
    "        \n",
    "        \n",
    "        #self.glove = Vocab.GloVe(name='840B', dim= embed_size)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, x, m = None, c = None, CNN = False ):\n",
    "        \n",
    "        if not CNN:\n",
    "            #glove requires x to be one hot word encoding?\n",
    "            #x = self.glove(x)\n",
    "            i = F.sigmoid(self.Wix(x)+self.Wim(m))\n",
    "            f = F.sigmoid(self.Wfx(x)+self.Wfm(m))\n",
    "            o = F.sigmoid(self.Wox(x)+self.Wom(m))\n",
    "            h = F.tanh(self.Wcx(x) + self.Wcm(m))\n",
    "            newC = f*c + i*h\n",
    "            newM = o*newC\n",
    "            #prediction dimension should line up with vocab_size\n",
    "            #fine tune hidden dimension to make that work\n",
    "            \n",
    "            #log_softmax might not be necessary -> due to backprop\n",
    "            \n",
    "            #calculations: hidden dimensions = 50, embed_size = 2048, vocab_size not used\n",
    "            #prediction = F.log_softmax(newM,)\n",
    "            \n",
    "            return newM, newC, newM\n",
    "        \n",
    "        else:\n",
    "            x = self.res50NoGrad(x)\n",
    "            x = self.res50Last(x)\n",
    "            x = x.resize(1, self.Esize)\n",
    "            i = F.sigmoid(self.Wix(x))\n",
    "            f = F.sigmoid(self.Wfx(x))\n",
    "            o = F.sigmoid(self.Wox(x))\n",
    "            h = F.tanh(self.Wcx(x))\n",
    "            c = i*h\n",
    "            m = o*c\n",
    "            \n",
    "            return None, c, m\n",
    "\n",
    "# net = LSTM(2048, 50, res)\n",
    "# img, target = cap[0]\n",
    "# img = img.unsqueeze(0)\n",
    "# junk, c0, m0 =  net.forward(Variable(img), CNN = True)\n",
    "\n",
    "# a = x.vectors[x.stoi['man']]\n",
    "# b = torch.FloatTensor(1998).zero_()\n",
    "# paddedVec = torch.cat((a, b), 0)\n",
    "\n",
    "# pred, c0, m0 = net.forward(Variable(paddedVec), m = m0, c = c0)\n",
    "# pred = pred.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0, LOSS: 0.300906306654\n",
      "EPOCH: 0, LOSS: 0.210703996718\n",
      "EPOCH: 0, LOSS: 0.205358923376\n",
      "EPOCH: 0, LOSS: 0.204190388471\n",
      "EPOCH: 0, LOSS: 0.192558823675\n",
      "EPOCH: 0, LOSS: 0.186805103868\n",
      "EPOCH: 0, LOSS: 0.186626527756\n",
      "EPOCH: 0, LOSS: 0.187759270966\n"
     ]
    }
   ],
   "source": [
    "##Train\n",
    "\n",
    "startW = 'start'\n",
    "endW = 'stop'\n",
    "## was lazy and used cat and dog as start and stop word. \n",
    "## Definetely going to have to change that\n",
    "net = LSTM(rSize, vdim, res)\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(filter(lambda p: p.requires_grad,net.parameters()), lr=0.001, momentum=.3)\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for epoch in range(0, 1000):\n",
    "    logLoss = 0.0\n",
    "    \n",
    "    torch.save(net, str(epoch)+'LSTM.pt')\n",
    "    for i in range(0, len(cap)):\n",
    "        img, target = cap[i]\n",
    "        words = [startW] + target[0].split(' ') + [endW]\n",
    "        length = len(words)\n",
    "        img = img.unsqueeze(0)\n",
    "        junk, c0, m0 =  net.forward(Variable(img), CNN = True)\n",
    "        fullPred = None\n",
    "        fullAnsw = None\n",
    "        flip = True\n",
    "        for j in range(0, length-1):\n",
    "            #Going to need larger word corpus\n",
    "            if words[j].lower() in x.stoi and words[j+1].lower() in x.stoi:\n",
    "\n",
    "                a = x.vectors[x.stoi[words[j].lower()]]\n",
    "                b = torch.FloatTensor(paddSize).zero_()\n",
    "                paddedVec = torch.cat((a, b), 0)\n",
    "                pred, c0, m0 = net.forward(Variable(paddedVec), m = m0, c = c0)\n",
    "\n",
    "                #temp = torch.FloatTensor(400000).zero_()\n",
    "                #temp[x.stoi[words[j+1].lower()]] = 1\n",
    "\n",
    "                answer = x.vectors[x.stoi[words[j+1].lower()]]\n",
    "                answer = answer.unsqueeze(0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                if flip:\n",
    "                    fullPred = pred\n",
    "                    fullAnsw = answer.unsqueeze(0)\n",
    "                    flip = False\n",
    "                else:\n",
    "                    answer = answer.unsqueeze(0)\n",
    "                    fullPred = torch.cat((fullPred, pred), 0)\n",
    "                    fullAnsw = torch.cat((fullAnsw, answer), 0)\n",
    "\n",
    "\n",
    "        \n",
    "        loss = criterion(fullPred, Variable(fullAnsw))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        logLoss += loss.data[0]\n",
    "        if counter % 100 == 99:    \n",
    "            print(\"EPOCH: \"+str(epoch) + \", LOSS: \" + str(logLoss/100))\n",
    "            logLoss = 0.0\n",
    "\n",
    "        counter+=1   \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
