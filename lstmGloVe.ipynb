{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project, COMS 4995_005, Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Information\n",
    "\n",
    "Team Member1 (Name,UNI): Richard Kennedy, rk2860\n",
    "\n",
    "Python Version: 2\n",
    "Utilizing Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cPickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torchtext.vocab as Vocab\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import PIL\n",
    "import random\n",
    "import numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=3.23s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "cap = dset.CocoCaptions(root = './train2014',\n",
    "                        annFile = 'annotations/captions_train2014.json',\n",
    "                        transform= transforms.Compose([transforms.Resize([224, 224]), transforms.ToTensor()]))\n",
    "\n",
    "res = models.resnet50(pretrained=True)\n",
    "vdim = 100\n",
    "rSize = 2048\n",
    "x = Vocab.GloVe(name='6B', dim= vdim)\n",
    "\n",
    "paddSize =  rSize - vdim\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "a = x.vectors[x.stoi['man']]\n",
    "print a.size()\n",
    "b = torch.FloatTensor(paddSize).zero_()\n",
    "paddedVec = torch.cat((a, b), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HELLO\n"
     ]
    }
   ],
   "source": [
    "print \"HELLO\"\n",
    "# img, target = cap[0]\n",
    "# words = ['StopLSTM'] + target[0].split(' ') + ['EndLSTM']\n",
    "# print words\n",
    "\n",
    "\n",
    "# print wordVec(Vocab[words[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size, res50):\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        self.Esize = embed_size\n",
    "        self.Hsize = hidden_size\n",
    "        self.Wix = nn.Linear(embed_size, hidden_size)\n",
    "        self.Wim = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Wfx = nn.Linear(embed_size, hidden_size)\n",
    "        self.Wfm = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Wox = nn.Linear(embed_size, hidden_size)\n",
    "        self.Wom = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Wcx = nn.Linear(embed_size, hidden_size)\n",
    "        self.Wcm = nn.Linear(hidden_size, hidden_size)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #res50 = torchvision.models.resnet50(pretrained=True)\n",
    "        self.res50NoGrad = torch.nn.Sequential(*list(res50.children())[:-2])\n",
    "        #Every layer besides the last layer does not need to be trained\n",
    "        for param in self.res50NoGrad.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        #set embed_size to dimensions of self.res50Last\n",
    "        #output should be second to last layer\n",
    "        self.res50Last = torch.nn.Sequential(list(res50.children())[-2])\n",
    "        \n",
    "        \n",
    "        #self.glove = Vocab.GloVe(name='840B', dim= embed_size)\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, x, m = None, c = None, CNN = False ):\n",
    "        \n",
    "        if not CNN:\n",
    "            #glove requires x to be one hot word encoding?\n",
    "            #x = self.glove(x)\n",
    "            i = F.sigmoid(self.Wix(x)+self.Wim(m))\n",
    "            f = F.sigmoid(self.Wfx(x)+self.Wfm(m))\n",
    "            o = F.sigmoid(self.Wox(x)+self.Wom(m))\n",
    "            h = F.tanh(self.Wcx(x) + self.Wcm(m))\n",
    "            newC = f*c + i*h\n",
    "            newM = o*newC\n",
    "            #prediction dimension should line up with vocab_size\n",
    "            #fine tune hidden dimension to make that work\n",
    "            \n",
    "            #log_softmax might not be necessary -> due to backprop\n",
    "            \n",
    "            #calculations: hidden dimensions = 50, embed_size = 2048, vocab_size not used\n",
    "            #prediction = F.log_softmax(newM,)\n",
    "            \n",
    "            \n",
    "            return newM, newC, newM\n",
    "        \n",
    "        else:\n",
    "            x = self.res50NoGrad(x)\n",
    "            x = self.res50Last(x)\n",
    "            x = x.resize(1, self.Esize)\n",
    "            i = F.sigmoid(self.Wix(x))\n",
    "            f = F.sigmoid(self.Wfx(x))\n",
    "            o = F.sigmoid(self.Wox(x))\n",
    "            h = F.tanh(self.Wcx(x))\n",
    "            c = i*h\n",
    "            m = o*c\n",
    "            \n",
    "            return None, c, m\n",
    "\n",
    "# net = LSTM(2048, 50, res)\n",
    "# img, target = cap[0]\n",
    "# img = img.unsqueeze(0)\n",
    "# junk, c0, m0 =  net.forward(Variable(img), CNN = True)\n",
    "\n",
    "# a = x.vectors[x.stoi['man']]\n",
    "# b = torch.FloatTensor(1998).zero_()\n",
    "# paddedVec = torch.cat((a, b), 0)\n",
    "\n",
    "# pred, c0, m0 = net.forward(Variable(paddedVec), m = m0, c = c0)\n",
    "# pred = pred.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0, LOSS: 0.0593814402819\n",
      "goals_none: 1, generals: 0\n",
      "EPOCH: 0, LOSS: 3.83510049302\n",
      "Tight 4: 159, generals: 245\n",
      "Tight 3: 66, Tight 4: 66\n",
      "EPOCH: 0, LOSS: 3.62973484613\n",
      "Tight 4: 186, generals: 221\n",
      "Tight 3: 78, Tight 4: 67\n",
      "EPOCH: 0, LOSS: 3.48856288608\n",
      "Tight 4: 249, generals: 178\n",
      "Tight 3: 92, Tight 4: 68\n",
      "EPOCH: 0, LOSS: 3.39372594897\n",
      "Tight 4: 303, generals: 159\n",
      "Tight 3: 98, Tight 4: 67\n",
      "EPOCH: 0, LOSS: 3.30913223397\n",
      "Tight 4: 326, generals: 151\n",
      "Tight 3: 118, Tight 4: 67\n",
      "EPOCH: 0, LOSS: 3.22523202069\n",
      "Tight 4: 358, generals: 140\n",
      "Tight 3: 143, Tight 4: 67\n",
      "EPOCH: 0, LOSS: 3.1833360743\n",
      "Tight 4: 380, generals: 128\n",
      "Tight 3: 160, Tight 4: 65\n",
      "EPOCH: 0, LOSS: 3.110310464\n",
      "Tight 4: 413, generals: 118\n",
      "Tight 3: 171, Tight 4: 69\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-b1f3b3840ad0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                 \u001b[0;31m#loss.data[0]+=lossPlus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Richard/anaconda2/lib/python2.7/site-packages/torch/autograd/variable.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Richard/anaconda2/lib/python2.7/site-packages/torch/autograd/__init__.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 99\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##Train\n",
    "\n",
    "\n",
    "startW = 'start'\n",
    "endW = 'stop'\n",
    "## was lazy and used cat and dog as start and stop word. \n",
    "## Definetely going to have to change that\n",
    "net = LSTM(rSize, vdim, res)\n",
    "net = torch.load('0trainLSTM.pt')\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.SGD(filter(lambda p: p.requires_grad,net.parameters()), lr=0.001, momentum=.6)\n",
    "\n",
    "counter = 0\n",
    "reinitialize = True\n",
    "for epoch in range(0, 1000):\n",
    "    permute = np.random.permutation(len(cap))\n",
    "    logLoss = 0.0\n",
    "    numGoals = 0\n",
    "    numGoalsT1 = 0\n",
    "    numGoalsT2 = 0\n",
    "    numGenerals = 0\n",
    "    localMins = 0\n",
    "    torch.save(net, str(epoch)+'LSTM.pt')\n",
    "    \n",
    "    for i in range(0, len(cap)):\n",
    "#         img, target = cap[permute[i]]\n",
    "        img, target = cap[i%20+10]\n",
    "        words = [startW] + target[0].split('.')[0].split(' ') + [endW]\n",
    "        \n",
    "        length = len(words)\n",
    "        \n",
    "        img = img.unsqueeze(0)\n",
    "        junk, c0, m0 =  net.forward(Variable(img), CNN = True)\n",
    "        fullPred = None\n",
    "        fullAnsw = None\n",
    "        flip = True\n",
    "        \n",
    "        \n",
    "        for j in range(0, length-1):\n",
    "            lossPlus = 0\n",
    "            #Going to need larger word corpus\n",
    "            if words[j].lower() in x.stoi and words[j+1].lower() in x.stoi:\n",
    "                \n",
    "                a = x.vectors[x.stoi[words[j].lower()]]\n",
    "                b = torch.FloatTensor(paddSize).zero_()\n",
    "                paddedVec = torch.cat((a, b), 0)\n",
    "                pred, c0, m0 = net.forward(Variable(paddedVec), m = m0, c = c0)\n",
    "                \n",
    "                \n",
    "              \n",
    "\n",
    "                answer = x.vectors[x.stoi[words[j+1].lower()]]\n",
    "                answer = answer.unsqueeze(0)\n",
    "                \n",
    "               \n",
    "                strKey = words[j+1].lower()\n",
    "#                 if reinitialize:\n",
    "#                     strKey = 'goals_none'\n",
    "#                     answer = x.vectors[x.stoi['non-families'.lower()]]\n",
    "#                     answer = answer.unsqueeze(0)\n",
    "                \n",
    "                \n",
    "                #Trying to remove the Local Minimums\n",
    "                dist1 = torch.dist(pred, Variable(answer)).data[0]\n",
    "                dist2 = torch.dist(pred, Variable(x.vectors[x.stoi[random.choice(x.stoi.keys())]])).data[0]\n",
    "                if abs(dist1 - dist2) <= .8 or dist1 >= dist2:\n",
    "                    numGenerals+=1\n",
    "                    \n",
    "                if torch.dist(pred, Variable(x.vectors[x.stoi[strKey]])).data[0] <= 4:\n",
    "                    \n",
    "                    numGoals+=1\n",
    "                    \n",
    "                    if torch.dist(pred, Variable(x.vectors[x.stoi[strKey]])).data[0] <= 3:\n",
    "                    \n",
    "                        numGoalsT1+=1\n",
    "                        \n",
    "                        if torch.dist(pred, Variable(x.vectors[x.stoi[strKey]])).data[0] <= 2:\n",
    "                    \n",
    "                            numGoalsT2+=1\n",
    "#                     answer = x.vectors[x.stoi['non-families'.lower()]]\n",
    "#                     answer = answer.unsqueeze(0)\n",
    "                    \n",
    "                \n",
    "               \n",
    "                \n",
    "#                 if dist1 < 3.5 and dist1 > 2.5:\n",
    "#                     localMins+= 1\n",
    "#                     lossPlus += .25\n",
    "               \n",
    "                \n",
    "                \n",
    "                loss = criterion(pred, Variable(answer))\n",
    "                \n",
    "                #loss.data[0]+=lossPlus\n",
    "                loss.backward(retain_graph = True)\n",
    "        \n",
    "                optimizer.step()\n",
    "\n",
    "                logLoss += loss.data[0]\n",
    "                #logLoss += lossPlus\n",
    "                if counter % 1000 == 999:    \n",
    "                    print(\"EPOCH: \"+str(epoch) + \", LOSS: \" + str(logLoss/100))\n",
    "                    print(\"Tight 4: \"+ str(numGoals) + \", generals: \"+str(numGenerals))\n",
    "                    print (\"Tight 3: \" + str(numGoalsT1) +', Tight 4: '+str(numGoalsT2))\n",
    "                    \n",
    "                    numGoals = 0\n",
    "                    numGenerals = 0\n",
    "                    numGoalsT1 = 0\n",
    "                    numGoalsT2 = 0\n",
    "                    logLoss = 0.0\n",
    "        \n",
    "                if counter == 0:\n",
    "                    print(\"EPOCH: \"+str(epoch) + \", LOSS: \" + str(logLoss))\n",
    "                    print(\"goals_none: \"+ str(numGoals) + \", generals: \"+str(numGenerals))\n",
    "                    \n",
    "                counter+=1   \n",
    "\n",
    "#                 if flip:\n",
    "#                     fullPred = pred.unsqueeze(0)\n",
    "#                     fullAnsw = answer.unsqueeze(0)\n",
    "#                     flip = False\n",
    "#                 else:\n",
    "#                     answer = answer.unsqueeze(0)\n",
    "#                     pred = pred.unsqueeze(0)\n",
    "#                     fullPred = torch.cat((fullPred, pred), 0)\n",
    "#                     fullAnsw = torch.cat((fullAnsw, answer), 0)\n",
    "                    \n",
    "        optimizer.zero_grad()         \n",
    "\n",
    "\n",
    "        \n",
    "#         loss = criterion(fullPred, Variable(fullAnsw))\n",
    "#         loss.data[0]+=lossPlus\n",
    "#         loss.backward()\n",
    "        \n",
    "#         optimizer.step()\n",
    "\n",
    "#         logLoss += loss.data[0]\n",
    "#         if counter % 100 == 99:    \n",
    "#             print(\"EPOCH: \"+str(epoch) + \", LOSS: \" + str(logLoss/100))\n",
    "#             logLoss = 0.0\n",
    "        \n",
    "#         if counter == 0:\n",
    "#             print(\"EPOCH: \"+str(epoch) + \", LOSS: \" + str(logLoss))\n",
    "\n",
    "#         counter+=1   \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'A tennis player is walking while holding his racket', u'Player and referee at tennis match on red court.', u'A man sitting on a high chair on a tennis court.', u\"A tennis player walks in front of the moderator's stand.\", u'A man on a court with a tennis racket.']\n",
      "[(u'a', Variable containing:\n",
      " 1.8085\n",
      "[torch.FloatTensor of size 1]\n",
      ")]\n",
      "a\n",
      "man\n",
      "stands\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-1e38cfb10ed2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mpaddedVec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaddedVec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mstrn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0mnewWord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mnewWord\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.save(net, str(epoch)+'trainLSTM.pt')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#net = LSTM(rSize, vdim, res)\n",
    "\n",
    "def createInverse(dic):\n",
    "    new_dic ={}\n",
    "    for key in dic:\n",
    "        new_dic[dic[key]] = key\n",
    "    \n",
    "    return new_dic\n",
    "\n",
    "invert = createInverse(x.stoi)\n",
    "\n",
    "def closest(vec, n=1):\n",
    "    \"\"\"\n",
    "    Find the closest words for a given vector\n",
    "    \"\"\"\n",
    "    all_dists = [(w,torch.dist(vec, Variable(x.vectors[x.stoi[w]]))) for w in x.stoi]\n",
    "    return sorted(all_dists, key=lambda t: t[1].data.numpy()[0])[:n]\n",
    "\n",
    "\n",
    "img, target = cap[55]\n",
    "print target\n",
    "img = img.unsqueeze(0)\n",
    "junk, c0, m0 =  net.forward(Variable(img), CNN = True)\n",
    "a = x.vectors[x.stoi['start'.lower()]]\n",
    "b = torch.FloatTensor(paddSize).zero_()\n",
    "paddedVec = torch.cat((a, b), 0)\n",
    "prediction, c0, m0 = net.forward(Variable(paddedVec), m = m0, c = c0)\n",
    "\n",
    "\n",
    "strn = closest(prediction, 1)\n",
    "print strn\n",
    "#print whenNotSorted(prediction.data[0])\n",
    "newWord = str(strn[0][0])\n",
    "print newWord\n",
    "#print strn\n",
    "while True:\n",
    "    a = x.vectors[x.stoi[newWord.lower()]]\n",
    "    b = torch.FloatTensor(paddSize).zero_()\n",
    "    paddedVec = torch.cat((a, b), 0)\n",
    "    prediction, c0, m0 = net.forward(Variable(paddedVec), m = m0, c = c0)\n",
    "    strn = closest(prediction, 1)\n",
    "    newWord = str(strn[0][0])\n",
    "    print newWord\n",
    "    #print strn\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'goals_none', Variable containing:\n",
      " 2.6643\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'65stk', Variable containing:\n",
      " 2.7356\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'__________________________________', Variable containing:\n",
      " 2.7474\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'prohertrib', Variable containing:\n",
      " 2.7507\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'http://www.oklahomacitynationalmemorial.org', Variable containing:\n",
      " 2.7676\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'tissottiming.com', Variable containing:\n",
      " 2.8126\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'____________________________________________', Variable containing:\n",
      " 2.8153\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'timewrn', Variable containing:\n",
      " 2.8185\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'_____________________________________________', Variable containing:\n",
      " 2.8302\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'www.slarmy.org', Variable containing:\n",
      " 2.8431\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'http://www.co.mo.md.us', Variable containing:\n",
      " 2.8616\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'nortelnet', Variable containing:\n",
      " 2.8627\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'dellcptr', Variable containing:\n",
      " 2.8732\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'likewise', Variable containing:\n",
      " 2.8736\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'30-270', Variable containing:\n",
      " 2.9003\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'http://www.nwguild.org', Variable containing:\n",
      " 2.9027\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'naborsind', Variable containing:\n",
      " 2.9378\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'devonengy', Variable containing:\n",
      " 2.9411\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'k587-1', Variable containing:\n",
      " 2.9422\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'mo95', Variable containing:\n",
      " 2.9434\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'http://www.mediabynumbers.com', Variable containing:\n",
      " 2.9440\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'k977-1', Variable containing:\n",
      " 2.9451\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'k978-1', Variable containing:\n",
      " 2.9455\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'js94bb', Variable containing:\n",
      " 2.9464\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'str95bb', Variable containing:\n",
      " 2.9468\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'bulletinyyy', Variable containing:\n",
      " 2.9470\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'srivalo', Variable containing:\n",
      " 2.9492\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'piyanart', Variable containing:\n",
      " 2.9493\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'bdb94', Variable containing:\n",
      " 2.9495\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'bb96', Variable containing:\n",
      " 2.9503\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'www.caib.us', Variable containing:\n",
      " 2.9647\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'brohd', Variable containing:\n",
      " 2.9725\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'kd97', Variable containing:\n",
      " 2.9781\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'http://www.nifc.gov/', Variable containing:\n",
      " 2.9810\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'biotechtrst', Variable containing:\n",
      " 2.9834\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'svahng', Variable containing:\n",
      " 2.9885\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'24aou94', Variable containing:\n",
      " 2.9922\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'instead', Variable containing:\n",
      " 2.9963\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'instance', Variable containing:\n",
      " 2.9977\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'goal_pittsburgh', Variable containing:\n",
      " 2.9987\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'kuhdz', Variable containing:\n",
      " 3.0022\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'bb94', Variable containing:\n",
      " 3.0023\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'brought', Variable containing:\n",
      " 3.0031\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'em96', Variable containing:\n",
      " 3.0049\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'moreover', Variable containing:\n",
      " 3.0106\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'js03', Variable containing:\n",
      " 3.0166\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'goal_florida', Variable containing:\n",
      " 3.0284\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'rohsh', Variable containing:\n",
      " 3.0448\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'presumably', Variable containing:\n",
      " 3.0452\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'organgn', Variable containing:\n",
      " 3.0501\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'js04bb', Variable containing:\n",
      " 3.0597\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'rw95', Variable containing:\n",
      " 3.0604\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'str94', Variable containing:\n",
      " 3.0642\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'nasdaq100', Variable containing:\n",
      " 3.0679\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'gph04bb', Variable containing:\n",
      " 3.0699\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'oly-2004-tennis', Variable containing:\n",
      " 3.0700\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'nokiacorp', Variable containing:\n",
      " 3.0773\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'besides', Variable containing:\n",
      " 3.0795\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'greg.wilcoxdailynews.com', Variable containing:\n",
      " 3.0801\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'coludata.co.uk', Variable containing:\n",
      " 3.0817\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'oly-2004-cycling', Variable containing:\n",
      " 3.0952\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'indnsia', Variable containing:\n",
      " 3.0970\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'rohch', Variable containing:\n",
      " 3.1073\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'goal_ottawa', Variable containing:\n",
      " 3.1079\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'goal_toronto', Variable containing:\n",
      " 3.1088\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'goal_boston', Variable containing:\n",
      " 3.1125\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'bringing', Variable containing:\n",
      " 3.1144\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'yr.ago', Variable containing:\n",
      " 3.1187\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'oly-2004-gymnastics', Variable containing:\n",
      " 3.1223\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'referring', Variable containing:\n",
      " 3.1273\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'http://www.statoil.com', Variable containing:\n",
      " 3.1314\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'meantime', Variable containing:\n",
      " 3.1373\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'supposed', Variable containing:\n",
      " 3.1401\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'noting', Variable containing:\n",
      " 3.1434\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'nasdaq100tr', Variable containing:\n",
      " 3.1465\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'genlelec', Variable containing:\n",
      " 3.1496\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'strikeouts_clemens', Variable containing:\n",
      " 3.1508\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'wc2003-wis', Variable containing:\n",
      " 3.1519\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'indeed', Variable containing:\n",
      " 3.1525\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'goal_montreal', Variable containing:\n",
      " 3.1544\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'interbk', Variable containing:\n",
      " 3.1548\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'pyoot', Variable containing:\n",
      " 3.1595\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'oly-2004-fhockey', Variable containing:\n",
      " 3.1643\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'turned', Variable containing:\n",
      " 3.1683\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'kd94', Variable containing:\n",
      " 3.1684\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'ooooooooooooooooooooooooooooooooooooooo', Variable containing:\n",
      " 3.1690\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'goal_colorado', Variable containing:\n",
      " 3.1766\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'canyonres', Variable containing:\n",
      " 3.1854\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'kd96', Variable containing:\n",
      " 3.1946\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'period_8', Variable containing:\n",
      " 3.1975\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'david.lazarus@latimes.com', Variable containing:\n",
      " 3.2005\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'28aou94', Variable containing:\n",
      " 3.2006\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'oly-2004-box', Variable containing:\n",
      " 3.2041\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'wrldcom', Variable containing:\n",
      " 3.2049\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'#ukqec', Variable containing:\n",
      " 3.2061\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'turning', Variable containing:\n",
      " 3.2071\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'http://www.storaenso.com', Variable containing:\n",
      " 3.2105\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'kd95', Variable containing:\n",
      " 3.2155\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'fahnt', Variable containing:\n",
      " 3.2216\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'404-222-8268', Variable containing:\n",
      " 3.2219\n",
      "[torch.FloatTensor of size 1]\n",
      ")]\n",
      "(u'goals_none', Variable containing:\n",
      " 2.6616\n",
      "[torch.FloatTensor of size 1]\n",
      ")\n",
      "Variable containing:\n",
      " 3.9846\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 4.8796\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print closest(prediction, 100)\n",
    "\n",
    "print strn[0]\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "print torch.dist(Variable(x.vectors[x.stoi[random.choice(x.stoi.keys())]]), Variable(x.vectors[x.stoi['goals_none']]))\n",
    "\n",
    "print torch.dist(Variable(x.vectors[x.stoi['snow']]), Variable(x.vectors[x.stoi['ice']]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 6.3827\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print torch.dist(Variable(x.vectors[x.stoi['vegetables']]), Variable(x.vectors[x.stoi['well']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEY\n",
      "[(u'non-families', Variable containing:\n",
      " 13.4806\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'republish', Variable containing:\n",
      " 12.1913\n",
      "[torch.FloatTensor of size 1]\n",
      "), (u'taiex', Variable containing:\n",
      " 11.3278\n",
      "[torch.FloatTensor of size 1]\n",
      ")]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print \"HEY\"\n",
    "def farthest(vec, n=1):\n",
    "    \"\"\"\n",
    "    Find the closest words for a given vector\n",
    "    \"\"\"\n",
    "    all_dists = [(w,torch.dist(vec, Variable(x.vectors[x.stoi[w]]))) for w in x.stoi]\n",
    "    return sorted(all_dists, key=lambda t: t[1].data.numpy()[0])[::-1][:n]\n",
    "\n",
    "a = x.vectors[x.stoi['instance'.lower()]]\n",
    "\n",
    "pred = farthest(Variable(a), 3)\n",
    "\n",
    "print pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
